# JMeter Results Publishing in Jenkins

## Overview
Multiple approaches to publish and visualize JMeter performance test results in Jenkins.

---

## Approach 1: publishHTML Plugin ‚úÖ (Recommended)

**What it does**: Publishes the JMeter HTML dashboard as an interactive report in Jenkins.

### Configuration:
```groovy
publishHTML(target: [
    reportDir: 'tests-perf/jmeter-report',
    reportFiles: 'index.html',
    reportName: 'JMeter Performance Report',
    keepAll: true,                    // Keep reports from all builds
    alwaysLinkToLastBuild: true       // Quick access to latest report
])
```

### Pros:
- ‚úÖ Rich visual dashboard with graphs
- ‚úÖ Built-in Jenkins plugin (no extra installation)
- ‚úÖ Interactive charts and statistics
- ‚úÖ Historical trend data

### Cons:
- ‚ùå No automatic pass/fail thresholds
- ‚ùå Requires HTML report generation (`-e -o` flags)

### Access:
Build page ‚Üí "JMeter Performance Report" link in sidebar

---

## Approach 2: Archive Artifacts

**What it does**: Stores raw JTL files for download and external analysis.

### Configuration:
```groovy
archiveArtifacts artifacts: 'tests-perf/jmeter-results.jtl',
                 allowEmptyArchive: false,
                 fingerprint: true
```

### Pros:
- ‚úÖ Raw data preservation
- ‚úÖ Can be analyzed with external tools
- ‚úÖ Fingerprinting for tracking changes
- ‚úÖ Downloadable for offline analysis

### Cons:
- ‚ùå No visualization in Jenkins
- ‚ùå Requires manual analysis

### Access:
Build page ‚Üí "Build Artifacts" ‚Üí Download JTL file

---

## Approach 3: Performance Plugin üîå (Advanced)

**What it does**: Provides trend analysis, thresholds, and build status based on performance metrics.

### Installation:
```bash
# Install via Jenkins Plugin Manager
Manage Jenkins ‚Üí Plugins ‚Üí Available ‚Üí "Performance Plugin"
```

### Configuration:
```groovy
perfReport sourceDataFiles: 'tests-perf/jmeter-results.jtl',
           errorFailedThreshold: 5,      // Mark build as FAILED if >5% errors
           errorUnstableThreshold: 2,    // Mark build as UNSTABLE if >2% errors
           errorUnstableResponseTimeThreshold: 'Health Check:500',  // 500ms threshold
           relativeFailedThresholdPositive: 10,  // Fail if 10% slower than previous
           relativeUnstableThresholdPositive: 5  // Unstable if 5% slower
```

### Pros:
- ‚úÖ Automatic pass/fail based on thresholds
- ‚úÖ Performance trend graphs across builds
- ‚úÖ Comparison with previous builds
- ‚úÖ Detailed metrics per request

### Cons:
- ‚ùå Requires plugin installation
- ‚ùå More complex configuration
- ‚ùå May need JTL format adjustments

### Access:
Build page ‚Üí "Performance Report" link

---

## Approach 4: JUnit Format (For Test Results)

**What it does**: Converts JMeter results to JUnit XML for test result tracking.

### Configuration:
```groovy
steps {
    sh '''
        jmeter -n -t bugtracker-jmeter.jmx -l jmeter-results.jtl -e -o jmeter-report
        
        # Convert JTL to JUnit XML (requires xslt processor)
        xsltproc /path/to/jmeter-results-to-junit.xsl jmeter-results.jtl > jmeter-junit.xml
    '''
}
post {
    always {
        junit 'tests-perf/jmeter-junit.xml'
    }
}
```

### Pros:
- ‚úÖ Integrates with Jenkins test result tracking
- ‚úÖ Shows pass/fail in test trends
- ‚úÖ Email notifications on failures

### Cons:
- ‚ùå Requires XSLT transformation
- ‚ùå Loses performance metrics detail
- ‚ùå Not ideal for performance data

---

## Approach 5: InfluxDB + Grafana (Enterprise)

**What it does**: Real-time metrics streaming to external monitoring system.

### Configuration:
```groovy
steps {
    sh '''
        jmeter -n -t bugtracker-jmeter.jmx \
               -l jmeter-results.jtl \
               -Jjmeter.save.saveservice.output_format=csv \
               -JinfluxdbUrl=http://influxdb:8086 \
               -JinfluxdbToken=mytoken
    '''
}
```

### Pros:
- ‚úÖ Real-time monitoring
- ‚úÖ Advanced visualization with Grafana
- ‚úÖ Long-term trend analysis
- ‚úÖ Alerting capabilities

### Cons:
- ‚ùå Requires external infrastructure
- ‚ùå Complex setup
- ‚ùå Additional maintenance

---

## Recommended Combination

For most projects, use **Approach 1 + 2**:

```groovy
post {
    always {
        // Visual dashboard
        publishHTML(target: [
            reportDir: 'tests-perf/jmeter-report',
            reportFiles: 'index.html',
            reportName: 'JMeter Performance Report',
            keepAll: true,
            alwaysLinkToLastBuild: true
        ])
        
        // Raw data archive
        archiveArtifacts artifacts: 'tests-perf/jmeter-results.jtl',
                         fingerprint: true
    }
}
```

For advanced needs, add **Approach 3** (Performance Plugin) for threshold-based build status.

---

## Comparison Table

| Approach | Visualization | Thresholds | Trends | Setup Complexity | Best For |
|----------|--------------|------------|--------|------------------|----------|
| publishHTML | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå | ‚≠ê‚≠ê‚≠ê | Low | Quick visual reports |
| Archive Artifacts | ‚ùå | ‚ùå | ‚ùå | Very Low | Data preservation |
| Performance Plugin | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Medium | CI/CD gates |
| JUnit Format | ‚≠ê‚≠ê | ‚úÖ | ‚≠ê‚≠ê‚≠ê | Medium | Test tracking |
| InfluxDB/Grafana | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | High | Enterprise monitoring |
